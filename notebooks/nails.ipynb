{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e753dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de89f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0296f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from skimage.color import rgb2lab, rgb2gray\n",
    "from skimage import img_as_float\n",
    "from scipy.stats import skew, kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101c30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class names and their corresponding labels\n",
    "class_names = ['anemic', 'Non-anemic']  \n",
    "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the dataset and split it into training, validation, and testing sets.\n",
    "    \"\"\"\n",
    "    dataset_dir = r'C:\\System\\Omar\\Omar Nile University\\Year 4\\Grad\\Mobile Application\\anemia_palm_api\\dataset\\Fingernails_dataset'\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    print(\"Loading dataset...\")\n",
    "\n",
    "    for folder in class_names:\n",
    "        folder_path = os.path.join(dataset_dir, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder '{folder}' does not exist in dataset directory.\")\n",
    "            continue\n",
    "        \n",
    "        label = class_names_label[folder]\n",
    "        \n",
    "        for file in tqdm(os.listdir(folder_path), desc=f\"Processing {folder}\"):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            image = cv2.imread(img_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Failed to load image {img_path}. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMAGE_SIZE)\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    images = np.array(images, dtype='float32')\n",
    "    labels = np.array(labels, dtype='int32')\n",
    "    \n",
    "    images, labels = shuffle(images, labels, random_state=25)\n",
    "    \n",
    "    # Splitting the data into 75% train, 10% validation, and 15% test\n",
    "    split_1 = int(0.75 * len(images))\n",
    "    split_2 = int(0.85 * len(images))\n",
    "    \n",
    "    train_images, train_labels = images[:split_1], labels[:split_1]\n",
    "    val_images, val_labels = images[split_1:split_2], labels[split_1:split_2]\n",
    "    test_images, test_labels = images[split_2:], labels[split_2:]\n",
    "\n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee990af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_color_features(images):\n",
    "    \"\"\"\n",
    "    Extract color features from a list of images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for img in images:\n",
    "        # Normalize the image (if necessary) to the range [0, 1]\n",
    "        img = img_as_float(img)\n",
    "\n",
    "        # Convert image to LAB color space\n",
    "        lab = rgb2lab(img)\n",
    "\n",
    "        # Extract L, A, B channels\n",
    "        L, A, B = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n",
    "\n",
    "        # Calculate statistical moments (mean, std, skew, kurtosis) for each channel\n",
    "        l_mean, l_std, l_skew, l_kurt = np.mean(L), np.std(L), skew(L.flatten()), kurtosis(L.flatten())\n",
    "        a_mean, a_std, a_skew, a_kurt = np.mean(A), np.std(A), skew(A.flatten()), kurtosis(A.flatten())\n",
    "        b_mean, b_std, b_skew, b_kurt = np.mean(B), np.std(B), skew(B.flatten()), kurtosis(B.flatten())\n",
    "\n",
    "        # Histograms for each channel (normalized)\n",
    "        l_hist, _ = np.histogram(L.flatten(), bins=256, range=(0, 100), density=True)\n",
    "        a_hist, _ = np.histogram(A.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "        b_hist, _ = np.histogram(B.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "\n",
    "        # Flatten histograms and concatenate with other features\n",
    "        hist_features = np.concatenate([l_hist, a_hist, b_hist])\n",
    "\n",
    "        # Combine all extracted features into a single feature vector\n",
    "        feature_vector = np.array([l_mean, l_std, l_skew, l_kurt, a_mean, a_std, a_skew, a_kurt, b_mean, b_std, b_skew, b_kurt])\n",
    "        feature_vector = np.concatenate([feature_vector, hist_features])\n",
    "\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af57ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing anemic: 100%|██████████| 2469/2469 [00:03<00:00, 686.40it/s] \n",
      "Processing Non-anemic: 100%|██████████| 1659/1659 [00:02<00:00, 812.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting color features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\System\\Downloads\\Python\\3.10.11\\lib\\site-packages\\numpy\\lib\\histograms.py:885: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3096\n",
      "Number of validation examples: 412\n",
      "Number of testing examples: 620\n",
      "Each image is of size: (224, 224)\n",
      "Feature vector length: 780\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = load_data()\n",
    "\n",
    "# Preprocess the images\n",
    "train_images = preprocess_input(train_images)\n",
    "val_images = preprocess_input(val_images)\n",
    "test_images = preprocess_input(test_images)\n",
    "\n",
    "# Extract color features\n",
    "print(\"Extracting color features...\")\n",
    "train_features = extract_color_features(train_images)\n",
    "val_features = extract_color_features(val_images)\n",
    "test_features = extract_color_features(test_images)\n",
    "\n",
    "# Dataset Statistics\n",
    "n_train = train_labels.shape[0]\n",
    "n_val = val_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print(f\"Number of training examples: {n_train}\")\n",
    "print(f\"Number of validation examples: {n_val}\")\n",
    "print(f\"Number of testing examples: {n_test}\")\n",
    "print(f\"Each image is of size: {IMAGE_SIZE}\")\n",
    "print(f\"Feature vector length: {train_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb75a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79b055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size after dropping nulls: 3033\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the features into a pandas DataFrame to easily handle missing values\n",
    "train_features_df = pd.DataFrame(train_features)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "train_features = train_features_df.dropna()\n",
    "\n",
    "# If labels also have missing values, drop them as well (ensure the feature and label arrays match)\n",
    "train_labels = train_labels[train_features.index]\n",
    "\n",
    "# Apply the same for validation and test sets\n",
    "val_features_df = pd.DataFrame(val_features)\n",
    "val_features = val_features_df.dropna()\n",
    "val_labels = val_labels[val_features.index]\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features)\n",
    "test_features = test_features_df.dropna()\n",
    "test_labels = test_labels[test_features.index]\n",
    "\n",
    "print(f\"Training set size after dropping nulls: {train_features.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0210489c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'get_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Step 1: Initialize and Train the Model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\__init__.py:998\u001b[0m\n\u001b[0;32m    992\u001b[0m     _log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded rc file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fname)\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    997\u001b[0m rcParamsDefault \u001b[38;5;241m=\u001b[39m _rc_params_in_file(\n\u001b[1;32m--> 998\u001b[0m     \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatplotlibrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# Strip leading comment.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m line: line[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m line,\n\u001b[0;32m   1001\u001b[0m     fail_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1002\u001b[0m rcParamsDefault\u001b[38;5;241m.\u001b[39m_update_raw(rcsetup\u001b[38;5;241m.\u001b[39m_hardcoded_defaults)\n\u001b[0;32m   1003\u001b[0m rcParamsDefault\u001b[38;5;241m.\u001b[39m_ensure_has_backend()\n",
      "File \u001b[1;32mc:\\System\\Downloads\\Python\\3.10.11\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:561\u001b[0m, in \u001b[0;36m_get_data_path\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_data_path\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    556\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03m    Return the `pathlib.Path` to a resource file provided by Matplotlib.\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m    ``*args`` specify a path relative to the base data path.\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_path\u001b[49m(), \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'get_data_path'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Initialize and Train the Model\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=8)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Step 2: Evaluate on Validation Set\n",
    "val_predictions = classifier.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
    "print(\"Validation Classification Report:\\n\", classification_report(val_labels, val_predictions))\n",
    "\n",
    "# Step 3: Evaluate on Test Set\n",
    "test_predictions = classifier.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "print(\"Test Classification Report:\\n\", classification_report(test_labels, test_predictions))\n",
    "\n",
    "# Step 4: Plot Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deafff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.98846787 0.97364086 0.99176277 0.9950495  0.99174917]\n",
      "Mean Cross-Validation Accuracy: 98.81%\n",
      "Standard Deviation of CV Accuracy: 0.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "cv_scores = cross_val_score(classifier, train_features, train_labels, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-Validation Accuracy: {:.2f}%\".format(np.mean(cv_scores) * 100))\n",
    "print(\"Standard Deviation of CV Accuracy: {:.2f}%\".format(np.std(cv_scores) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf33ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at random_forest_model_nails.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Step 1: Save the trained model\n",
    "model_path = \"random_forest_model_nails.joblib\"\n",
    "joblib.dump(classifier, model_path)\n",
    "print(f\"Model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997dbb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Extracted feature vector shape: (1, 780)\n",
      "The predicted class for the image is: Non-anemic\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2lab\n",
    "from scipy.stats import skew, kurtosis\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "import joblib\n",
    "\n",
    "# Class names and their corresponding labels\n",
    "class_names = ['anemic', 'Non-anemic']  \n",
    "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "def extract_color_features(images):\n",
    "    \"\"\"\n",
    "    Extract color features from a list of images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for img in images:\n",
    "        # Normalize the image (if necessary) to the range [0, 1]\n",
    "        img = img_as_float(img)\n",
    "\n",
    "        # Convert image to LAB color space\n",
    "        lab = rgb2lab(img)\n",
    "\n",
    "        # Extract L, A, B channels\n",
    "        L, A, B = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n",
    "\n",
    "        # Calculate statistical moments (mean, std, skew, kurtosis) for each channel\n",
    "        l_mean, l_std, l_skew, l_kurt = np.mean(L), np.std(L), skew(L.flatten()), kurtosis(L.flatten())\n",
    "        a_mean, a_std, a_skew, a_kurt = np.mean(A), np.std(A), skew(A.flatten()), kurtosis(A.flatten())\n",
    "        b_mean, b_std, b_skew, b_kurt = np.mean(B), np.std(B), skew(B.flatten()), kurtosis(B.flatten())\n",
    "\n",
    "        # Histograms for each channel (normalized)\n",
    "        l_hist, _ = np.histogram(L.flatten(), bins=256, range=(0, 100), density=True)\n",
    "        a_hist, _ = np.histogram(A.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "        b_hist, _ = np.histogram(B.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "\n",
    "        # Flatten histograms and concatenate with other features\n",
    "        hist_features = np.concatenate([l_hist, a_hist, b_hist])\n",
    "\n",
    "        # Combine all extracted features into a single feature vector\n",
    "        feature_vector = np.array([l_mean, l_std, l_skew, l_kurt, a_mean, a_std, a_skew, a_kurt, b_mean, b_std, b_skew, b_kurt])\n",
    "        feature_vector = np.concatenate([feature_vector, hist_features])\n",
    "\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess a single image to prepare it for prediction.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"The image file '{image_path}' does not exist.\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n",
    "\n",
    "    # Convert to RGB and resize to the required input size\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    # Normalize and preprocess the image\n",
    "    image = preprocess_input(image.astype(\"float32\"))\n",
    "\n",
    "    # Extract color features\n",
    "    features = extract_color_features([image])  # Extract features for a single image\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_image(image_path, model_path, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the loaded model.\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Preprocess the input image and extract features\n",
    "    features = preprocess_single_image(image_path)\n",
    "\n",
    "    # Debugging: Check feature vector shape\n",
    "    print(f\"Extracted feature vector shape: {features.shape}\")\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(features)  # Ensure model expects shape (1, n_features)\n",
    "    predicted_label = class_names[int(prediction[0])]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Example Usage\n",
    "image_path = r\"D:\\Mousa\\Nile University\\Grad\\Phase 1\\Nails\\nails\\test\\Non-Anrmic-FN-009 (6).png\"  # Replace with your image path\n",
    "model_path = r\"D:\\Mousa\\Nile University\\Grad\\Phase 1\\Nails\\nails\\random_forest_model_nails.joblib\"  # Replace with your trained model path\n",
    "try:\n",
    "    predicted_class = predict_image(image_path, model_path, class_names)\n",
    "    print(f\"The predicted class for the image is: {predicted_class}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d875c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Extracted feature vector shape: (1, 780)\n",
      "The predicted class for the image is: Non-anemic\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2lab\n",
    "from scipy.stats import skew, kurtosis\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "import joblib\n",
    "\n",
    "# Class names and their corresponding labels\n",
    "class_names = ['anemic', 'Non-anemic']  \n",
    "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "def extract_color_features(images):\n",
    "    \"\"\"\n",
    "    Extract color features from a list of images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for img in images:\n",
    "        # Normalize the image (if necessary) to the range [0, 1]\n",
    "        img = img_as_float(img)\n",
    "\n",
    "        # Convert image to LAB color space\n",
    "        lab = rgb2lab(img)\n",
    "\n",
    "        # Extract L, A, B channels\n",
    "        L, A, B = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n",
    "\n",
    "        # Calculate statistical moments (mean, std, skew, kurtosis) for each channel\n",
    "        l_mean, l_std, l_skew, l_kurt = np.mean(L), np.std(L), skew(L.flatten()), kurtosis(L.flatten())\n",
    "        a_mean, a_std, a_skew, a_kurt = np.mean(A), np.std(A), skew(A.flatten()), kurtosis(A.flatten())\n",
    "        b_mean, b_std, b_skew, b_kurt = np.mean(B), np.std(B), skew(B.flatten()), kurtosis(B.flatten())\n",
    "\n",
    "        # Histograms for each channel (normalized)\n",
    "        l_hist, _ = np.histogram(L.flatten(), bins=256, range=(0, 100), density=True)\n",
    "        a_hist, _ = np.histogram(A.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "        b_hist, _ = np.histogram(B.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "\n",
    "        # Flatten histograms and concatenate with other features\n",
    "        hist_features = np.concatenate([l_hist, a_hist, b_hist])\n",
    "\n",
    "        # Combine all extracted features into a single feature vector\n",
    "        feature_vector = np.array([l_mean, l_std, l_skew, l_kurt, a_mean, a_std, a_skew, a_kurt, b_mean, b_std, b_skew, b_kurt])\n",
    "        feature_vector = np.concatenate([feature_vector, hist_features])\n",
    "\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess a single image to prepare it for prediction.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"The image file '{image_path}' does not exist.\")\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n",
    "\n",
    "    # Convert to RGB and resize to the required input size\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "    # Normalize and preprocess the image\n",
    "    image = preprocess_input(image.astype(\"float32\"))\n",
    "\n",
    "    # Extract color features\n",
    "    features = extract_color_features([image])  # Extract features for a single image\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_image(image_path, model_path, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the loaded model.\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Preprocess the input image and extract features\n",
    "    features = preprocess_single_image(image_path)\n",
    "\n",
    "    # Debugging: Check feature vector shape\n",
    "    print(f\"Extracted feature vector shape: {features.shape}\")\n",
    "\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(features)  # Ensure model expects shape (1, n_features)\n",
    "    predicted_label = class_names[int(prediction[0])]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Example Usage\n",
    "image_path = r\"D:\\Mousa\\Nile University\\Grad\\Phase 1\\Nails\\nails\\test\\Non-anemic-Fin-004 (2).png\"  # Replace with your image path\n",
    "model_path = r\"D:\\Mousa\\Nile University\\Grad\\Phase 1\\Nails\\nails\\random_forest_model_nails.joblib\"  # Replace with your trained model path\n",
    "try:\n",
    "    predicted_class = predict_image(image_path, model_path, class_names)\n",
    "    print(f\"The predicted class for the image is: {predicted_class}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a604f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2lab\n",
    "from scipy.stats import skew, kurtosis\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Class names and their corresponding labels\n",
    "class_names = ['anemic', 'Non-anemic']  \n",
    "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "def extract_color_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img = img_as_float(img)\n",
    "        lab = rgb2lab(img)\n",
    "        L, A, B = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n",
    "\n",
    "        l_mean, l_std, l_skew, l_kurt = np.mean(L), np.std(L), skew(L.flatten()), kurtosis(L.flatten())\n",
    "        a_mean, a_std, a_skew, a_kurt = np.mean(A), np.std(A), skew(A.flatten()), kurtosis(A.flatten())\n",
    "        b_mean, b_std, b_skew, b_kurt = np.mean(B), np.std(B), skew(B.flatten()), kurtosis(B.flatten())\n",
    "\n",
    "        l_hist, _ = np.histogram(L.flatten(), bins=256, range=(0, 100), density=True)\n",
    "        a_hist, _ = np.histogram(A.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "        b_hist, _ = np.histogram(B.flatten(), bins=256, range=(-128, 128), density=True)\n",
    "\n",
    "        hist_features = np.concatenate([l_hist, a_hist, b_hist])\n",
    "\n",
    "        feature_vector = np.array([l_mean, l_std, l_skew, l_kurt, a_mean, a_std, a_skew, a_kurt, b_mean, b_std, b_skew, b_kurt])\n",
    "        feature_vector = np.concatenate([feature_vector, hist_features])\n",
    "\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"The image file '{image_path}' does not exist.\")\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image from '{image_path}'.\")\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "    image = preprocess_input(image.astype(\"float32\"))\n",
    "\n",
    "    features = extract_color_features([image])\n",
    "\n",
    "    return features\n",
    "\n",
    "def predict_image(image_path, model_path, class_names):\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    features = preprocess_single_image(image_path)\n",
    "    \n",
    "    prediction = model.predict(features)\n",
    "    predicted_label = class_names[int(prediction[0])]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "def browse_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg\")])\n",
    "    if file_path:\n",
    "        image_label.config(text=f\"Selected Image: {os.path.basename(file_path)}\")\n",
    "        display_image(file_path)\n",
    "        result_label.config(text=\"\")\n",
    "        advice_label.config(text=\"\")\n",
    "        predict_button.config(state=tk.NORMAL, command=lambda: predict_and_display(file_path))  # Enable the predict button\n",
    "\n",
    "def display_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((200, 200))\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "    image_panel.config(image=img_tk)\n",
    "    image_panel.image = img_tk\n",
    "\n",
    "def give_advice(predicted_class):\n",
    "    if predicted_class == 'anemic':\n",
    "        return \"It is advisable to seek medical advice and consider iron-rich foods, supplements, or further medical tests.\"\n",
    "    else:\n",
    "        return \"Your results indicate no anemia, but maintaining a healthy diet is still recommended.\"\n",
    "\n",
    "def predict_and_display(image_path):\n",
    "    model_path = r\"D:\\Mousa\\Nile University\\Grad\\Phase 1\\Nails\\nails\\random_forest_model_nails.joblib\"\n",
    "    try:\n",
    "        predicted_class = predict_image(image_path, model_path, class_names)\n",
    "        result_label.config(text=f\"Predicted Class: {predicted_class}\", fg=\"green\" if predicted_class == 'Non-anemic' else \"red\")\n",
    "        advice = give_advice(predicted_class)\n",
    "        advice_label.config(text=advice, fg=\"blue\")\n",
    "    except Exception as e:\n",
    "        result_label.config(text=f\"Error: {str(e)}\", fg=\"red\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Anemia Detection using Image\")\n",
    "root.config(bg=\"#f0f0f0\")\n",
    "\n",
    "frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "frame.pack(padx=20, pady=20)\n",
    "\n",
    "browse_button = tk.Button(frame, text=\"Browse Image\", command=browse_image, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12, \"bold\"))\n",
    "browse_button.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "image_label = tk.Label(frame, text=\"No image selected\", bg=\"#f0f0f0\", font=(\"Arial\", 10))\n",
    "image_label.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "image_panel = tk.Label(frame, bg=\"#f0f0f0\")\n",
    "image_panel.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "predict_button = tk.Button(frame, text=\"Predict\", state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12, \"bold\"))  # Initially disabled\n",
    "predict_button.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "result_label = tk.Label(frame, text=\"\", bg=\"#f0f0f0\", font=(\"Arial\", 12, \"bold\"))\n",
    "result_label.grid(row=4, column=0, padx=10, pady=10)\n",
    "\n",
    "advice_label = tk.Label(frame, text=\"\", bg=\"#f0f0f0\", font=(\"Arial\", 12, \"italic\"))\n",
    "advice_label.grid(row=5, column=0, padx=10, pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
